{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo parsing the data using longitude, latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d352b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import time\n",
    "import pickle\n",
    "import geoplotlib\n",
    "import pandas as pd\n",
    "from geoplotlib.utils import read_csv as read_csv2\n",
    "from shapely.geometry import Point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3cb7a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo columns from original dataset\n",
    "columns_geo = [\"lat\", \"id\", \"long\"]\n",
    "\n",
    "# Setup locator\n",
    "locator = Nominatim(user_agent= \"xz@gmail.com\" )\n",
    "\n",
    "#Load data\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\")\n",
    "\n",
    "# Make test dataframe\n",
    "test_df = data[columns_geo].iloc[0:5]\n",
    "\n",
    "# Make sample dataframe for exploratory data analysis and finding features to fit the model.\n",
    "# Frac = the percentage of original dataframe (0.1 corresponds to 10%)\n",
    "sample_df = data[columns_geo].sample(frac = 0.03)\n",
    "\n",
    "\n",
    "# List of possible address fields\n",
    "raw_address_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0dd5185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21597, 14)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of locator function \n",
    "location = locator.reverse([test_df[\"lat\"][0],test_df[\"long\"][0]])\n",
    "location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9134314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The process of parsing data for our dataframe from OSM takes a long time due to limitation: 1 request per second.\n",
    "# For 21000 records it will take more than 6 hours. We need to create functions to save data during the process of saving as well as continue where we finished the process.\n",
    "# Function to check if the record already exist\n",
    "\n",
    "def nan_equal(a,b):\n",
    "        try:\n",
    "            np.testing.assert_equal(a,b)\n",
    "        except AssertionError:\n",
    "            return False\n",
    "        return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eca2bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore function\n",
    "\n",
    "def geoloc_explore(record, raw_address_list):\n",
    "    lat = record[\"lat\"]\n",
    "    lon = record[\"long\"]\n",
    "    location = locator.reverse([lat,lon]) \n",
    "    raw_address_list.append(location.raw)\n",
    "    time.sleep(1)             # 1 second delay due to OSM parsing limitations\n",
    "    if (i % 50 == 0):\n",
    "        print(f\"record {i}\")  # Check the progress\n",
    "    if (i % 150 == 0):\n",
    "        with open('./data/Geo_raw_file.pickle', 'wb') as f:   # Save the data\n",
    "            pickle.dump(raw_address_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "            print(\"Pickled\")\n",
    "    return raw_address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "97944fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73dc4f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records with missing cities 779\n",
      "Missing values are in 3.61 % of data\n"
     ]
    }
   ],
   "source": [
    "# Optional load of sample dataset from pickle\n",
    "# Load already processed data (uncomment to proceed)\n",
    "# with open('./data/Geo_raw_file.pickle', 'rb') as f:\n",
    "#     raw_address_list = pickle.load(f)\n",
    "\n",
    "# Explore Sample dataset for unqiue features (uncomment to proceed)\n",
    "\n",
    "for i in range(len(sample_df)):\n",
    "        raw_address_list = geoloc_explore(sample_df.iloc[i], raw_address_list)\n",
    "\n",
    "# Final pickle of acquired data\n",
    "with open('./data/Geo_raw_file.pickle', 'wb') as f:\n",
    "            pickle.dump(raw_address_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Data is pickled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9980466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20814, 12)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1dcd6409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records with missing values 0\n"
     ]
    }
   ],
   "source": [
    "# Investigate \"Type_place\" column for missing values\n",
    "print(f\"The number of records with missing values {sum(df_geo.Type_place.isna())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c617aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dig deeper into usage of different fields, to find patterns that can be used later during data exploration\n",
    "# features_search must be changed to each value from feature_list, to find pattern of data\n",
    "features_search_list = []\n",
    "features_search = \"town\"\n",
    "for address in raw_address_list:\n",
    "    address_features = list(address[\"address\"].keys())\n",
    "    if features_search in address_features:\n",
    "        features_search_list.append(address)\n",
    "features_search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7999202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional check for \"type of cities involved\"\n",
    "# features_search_list = []\n",
    "# features_search = [\"city\", \"town\", \"village\"]\n",
    "# for address in raw_address_list:\n",
    "#     address_features = list(address[\"address\"].keys())\n",
    "#     if (features_search[0] not in address_features) and (features_search[1] not in address_features) and (features_search[2] not in address_features)  :\n",
    "#         features_search_list.append(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 3 types of locations: towns, cities, villages. Some of them use different names for suburbs - suburbs, hamlet etc. \n",
    "All this information should be used to create correct dataframe later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to parse data\n",
    "def geoloc(record):\n",
    "    lat = record[\"lat\"]\n",
    "    lon = record[\"long\"]\n",
    "    print(lat, lon)\n",
    "    location = locator.reverse([lat,lon]) \n",
    "    time.sleep(1)\n",
    "    return location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b13bcd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on previous analysis we created new features list for our dataframe\n",
    "New_features_list = [\"To_drop_place_ID\", \"To_drop_road\", \"Type_place\", \"city\", \"county\" , \"state\" , \"suburb\" ]\n",
    "\n",
    "# Create new geo dataframe\n",
    "df_geo = data[columns_geo].copy()\n",
    "\n",
    "# Add new features\n",
    "df_geo[New_features_list] = np.NAN\n",
    "\n",
    "# Check new DataFrame\n",
    "\n",
    "print(f\"The number of records {len(df_geo)}\")\n",
    "display(df_geo.head())\n",
    "display(df_geo.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "acceec17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c810a8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'] = 2022 - df['yr_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "542abebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renovated (year):\n",
    "    \"\"\"\n",
    "    This returns a True / False value on whether a property has been renovated or not\n",
    "    \"\"\"\n",
    "    if year == 0.0:\n",
    "        return False\n",
    "    elif year > 0.0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "df['renovated'] = df['yr_renovated'].map(renovated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d3094f35",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
