{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54561808",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb4bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8659f784",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60333a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85269af8",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955411d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7d2df90",
   "metadata": {},
   "source": [
    "## Geo parsing the data using longitude, latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0823f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import time\n",
    "import pickle\n",
    "import geoplotlib\n",
    "import pandas as pd\n",
    "from geoplotlib.utils import read_csv as read_csv2\n",
    "from shapely.geometry import Point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4c971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo columns from original dataset\n",
    "columns_geo = [\"lat\", \"id\", \"long\"]\n",
    "\n",
    "# Setup locator\n",
    "locator = Nominatim(user_agent= \"xz@gmail.com\" )\n",
    "\n",
    "#Load data\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\")\n",
    "\n",
    "# Make test dataframe\n",
    "test_df = data[columns_geo].iloc[0:5]\n",
    "\n",
    "# Make sample dataframe for exploratory data analysis and finding features to fit the model.\n",
    "# Frac = the percentage of original dataframe (0.1 corresponds to 10%)\n",
    "sample_df = data[columns_geo].sample(frac = 0.03)\n",
    "\n",
    "\n",
    "# List of possible address fields\n",
    "raw_address_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8bebad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'place_id': 159583259,\n",
       " 'licence': 'Data Â© OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright',\n",
       " 'osm_type': 'way',\n",
       " 'osm_id': 236673600,\n",
       " 'lat': '47.5112302',\n",
       " 'lon': '-122.25676111324441',\n",
       " 'display_name': '10012, 61st Avenue South, Rainier Beach, Seattle, King County, Washington, 98178, United States',\n",
       " 'address': {'house_number': '10012',\n",
       "  'road': '61st Avenue South',\n",
       "  'neighbourhood': 'Rainier Beach',\n",
       "  'city': 'Seattle',\n",
       "  'county': 'King County',\n",
       "  'state': 'Washington',\n",
       "  'postcode': '98178',\n",
       "  'country': 'United States',\n",
       "  'country_code': 'us'},\n",
       " 'boundingbox': ['47.511189', '47.5112943', '-122.2568571', '-122.2566651']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of locator function \n",
    "location = locator.reverse([test_df[\"lat\"][0],test_df[\"long\"][0]])\n",
    "location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773021d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The process of parsing data for our dataframe from OSM takes a long time due to limitation: 1 request per second.\n",
    "# For 21000 records it will take more than 6 hours. We need to create functions to save data during the process of saving as well as continue where we finished the process.\n",
    "# Function to check if the record already exist\n",
    "\n",
    "def nan_equal(a,b):\n",
    "        try:\n",
    "            np.testing.assert_equal(a,b)\n",
    "        except AssertionError:\n",
    "            return False\n",
    "        return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1369bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore function\n",
    "\n",
    "def geoloc_explore(record, raw_address_list):\n",
    "    lat = record[\"lat\"]\n",
    "    lon = record[\"long\"]\n",
    "    location = locator.reverse([lat,lon]) \n",
    "    raw_address_list.append(location.raw)\n",
    "    time.sleep(1)             # 1 second delay due to OSM parsing limitations\n",
    "    if (i % 50 == 0):\n",
    "        print(f\"record {i}\")  # Check the progress\n",
    "    if (i % 150 == 0):\n",
    "        with open('./data/Geo_raw_file.pickle', 'wb') as f:   # Save the data\n",
    "            pickle.dump(raw_address_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "            print(\"Pickled\")\n",
    "    return raw_address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ffe6a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bf643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record 0\n",
      "Pickled\n",
      "record 50\n",
      "record 100\n",
      "record 150\n",
      "Pickled\n",
      "record 200\n",
      "record 250\n",
      "record 300\n",
      "Pickled\n",
      "record 350\n"
     ]
    }
   ],
   "source": [
    "# Optional load of sample dataset from pickle\n",
    "# Load already processed data (uncomment to proceed)\n",
    "with open('./data/Geo_raw_file.pickle', 'rb') as f:\n",
    "    raw_address_list = pickle.load(f)\n",
    "\n",
    "# Explore Sample dataset for unqiue features (uncomment to proceed)\n",
    "\n",
    "for i in range(len(sample_df)):\n",
    "        raw_address_list = geoloc_explore(sample_df.iloc[i], raw_address_list)\n",
    "\n",
    "    \n",
    "print(f\"File contains {len(raw_address_list)} records\")\n",
    "\n",
    "# Final pickle of acquired data\n",
    "with open('./data/Geo_raw_file.pickle', 'wb') as f:\n",
    "            pickle.dump(raw_address_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Data is pickled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cab7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional load of sample dataset from pickle\n",
    "# Load already processed data (uncomment to proceed)\n",
    "with open('./data/Geo_raw_file.pickle', 'rb') as f:\n",
    "    raw_address_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_address_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f351ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find possible features and create features frequency dictionary\n",
    "feature_list={}\n",
    "for address in raw_address_list:\n",
    "        address_features = list(address[\"address\"].keys())\n",
    "        for feature in address_features:\n",
    "            if feature not in feature_list:\n",
    "                feature_list[feature] = 1\n",
    "            else:\n",
    "                feature_list[feature] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore frequency dictionary\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dig deeper into usage of different fields, to find patterns that can be used later during data exploration\n",
    "# features_search must be changed to each value from feature_list, to find pattern of data\n",
    "features_search_list = []\n",
    "features_search = \"town\"\n",
    "for address in raw_address_list:\n",
    "    address_features = list(address[\"address\"].keys())\n",
    "    if features_search in address_features:\n",
    "        features_search_list.append(address)\n",
    "features_search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional check for \"type of cities involved\"\n",
    "# features_search_list = []\n",
    "# features_search = [\"city\", \"town\", \"village\"]\n",
    "# for address in raw_address_list:\n",
    "#     address_features = list(address[\"address\"].keys())\n",
    "#     if (features_search[0] not in address_features) and (features_search[1] not in address_features) and (features_search[2] not in address_features)  :\n",
    "#         features_search_list.append(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf08433a",
   "metadata": {},
   "source": [
    "We can see that there are 3 types of locations: towns, cities, villages. Some of them use different names for suburbs - suburbs, hamlet etc. \n",
    "All this information should be used to create correct dataframe later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to parse data\n",
    "def geoloc(record):\n",
    "    lat = record[\"lat\"]\n",
    "    lon = record[\"long\"]\n",
    "    print(lat, lon)\n",
    "    location = locator.reverse([lat,lon]) \n",
    "    time.sleep(1)\n",
    "    return location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98323bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on previous analysis we created new features list for our dataframe\n",
    "New_features_list = [\"To_drop_place_ID\", \"To_drop_road\", \"Type_place\", \"city\", \"county\" , \"state\" , \"suburb\" ]\n",
    "\n",
    "# Create new geo dataframe\n",
    "df_geo = data[columns_geo].copy()\n",
    "\n",
    "# Add new features\n",
    "df_geo[New_features_list] = np.NAN\n",
    "\n",
    "# Check new DataFrame\n",
    "\n",
    "print(f\"The number of records {len(df_geo)}\")\n",
    "display(df_geo.head())\n",
    "display(df_geo.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c8917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already processed data (uncomment to proceed)\n",
    "with open('./data/Data_frame_geoloc.pickle', 'rb') as df_geo_data:\n",
    "     df_geo = pickle.load(df_geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8475aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing algorithm based on previous data exploration\n",
    "\n",
    "for i in range(len(df_geo)):\n",
    "    if nan_equal(df_geo[\"state\"][i],\"Washington\"):  #Check if record already exist\n",
    "        if (i % 100 == 0):\n",
    "            print(f\"Record {i} exist\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"New_record{i}\")\n",
    "        data = geoloc(df_geo.iloc[i])\n",
    "        df_geo[\"To_drop_place_ID\"][i]=data.get(\"place_id\")\n",
    "        df_geo[\"To_drop_road\"][i]=data.get(\"address\").get(\"road\")\n",
    "        df_geo[\"county\"][i]=data.get(\"address\").get(\"county\")\n",
    "        df_geo[\"state\"][i]=data.get(\"address\").get(\"state\")\n",
    "        if \"city\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"city\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"city\")\n",
    "        elif \"town\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"town\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"town\")\n",
    "        elif \"village\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"village\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"village\")\n",
    "        else:\n",
    "            df_geo[\"Type_place\"][i] = np.NAN\n",
    "            df_geo[\"city\"][i] = np.NAN \n",
    "        if \"suburb\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"suburb\"][i] = data.get(\"address\").get(\"suburb\")\n",
    "        elif \"hamlet\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"suburb\"][i] = data.get(\"address\").get(\"hamlet\")\n",
    "                                            \n",
    "        if (i % 100 == 0):\n",
    "            with open('./data/Data_frame_geoloc.pickle', 'wb') as df_geo_data:   #Save data, each 150 iterations\n",
    "                pickle.dump(df_geo, df_geo_data, pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"Pickled\", i) \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac69d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe after parsing\n",
    "print(f\"The number of records {len(df_geo)}\")\n",
    "display(df_geo.head())\n",
    "display(df_geo.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "with open('./data/Data_frame_geoloc.pickle', 'wb') as df_geo_data:   \n",
    "                pickle.dump(df_geo, df_geo_data, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Pickled\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872defd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already processed data (uncomment to proceed)\n",
    "# with open('./data/Data_frame_geoloc.pickle', 'rb') as df_geo_data:\n",
    "#     df_geo = pickle.load(df_geo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f6265",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352b4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d16d35f7",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810a8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1042522c",
   "metadata": {},
   "source": [
    "# Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7066f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c6da7d",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893e852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
